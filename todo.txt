ToDo:
- Expand Acted with more gestures and distance
- readme (instructions)

# Final -> Remove history

Enhance/advance
- Check frame limit (> 8)
- Can "body description" enhancement method be used on full video?
- Classifiy across whole video
- Write about which models uses what. And methods. Full video, path, frame_list, etc.

- Look into:
python models/archive/vllama3.py --video_folder "../actedgestures/Follow.MP4" --prompt "Explain what the person is during in details, for an LLM to interpret the gesture. Each frame has supplementary information about the pose"
Loading checkpoint shards: 100%|████| 4/4 [00:02<00:00,  1.81it/s]
/home/mi3/.cache/huggingface/modules/transformers_modules/DAMO-NLP-SG/VideoLLaMA3-7B/a498675483e2be8e98d092a2cb11a608c2caa8dd/modeling_videollama3.py:384: FutureWarning: `num_logits_to_keep` is deprecated and will be removed in version 4.50 for `Videollama3Qwen2ForCausalLM.forward`. Use `logits_to_keep` instead.
  return super().forward(
Caption: The person is standing in front of a white wall, wearing glasses and a black long-sleeved shirt. Initially facing the camera with his arms at his sides, he raises his right hand to wave before lowering it again. He then turns slightly to his left while maintaining eye contact with the viewer. After turning back towards the center, his head moves down as if looking at something on the ground or adjusting his posture. Finally, the video ends abruptly without showing any further actions from him.